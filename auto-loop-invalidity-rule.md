# Automated Development Loop â€“ Procedural Invalidity Rule

This rule applies to AI systems involved in iterative self-improvement,
automated testing, or performance optimization pipelines.

It does not prohibit development.
It defines conditions under which approval is procedurally invalid.

---

## 1. AI Evaluation Non-Sufficiency

AI-generated evaluation results,
performance metrics,
or optimization outputs
shall not constitute sufficient grounds for approval.

Human written justification is mandatory.

---

## 2. Human Judgment Requirement

For each major release, update, or deployment:

- A named human reviewer must provide written reasoning.
- The reasoning must address why continuation was not stopped.
- Mere acknowledgment of AI outputs is insufficient.

If no written reasoning exists,
approval is invalid.

---

## 3. Closed-Loop Prohibition (Procedural)

If an AI system:

- Generates its own evaluation criteria,
- Evaluates its own outputs,
- Approves its own modifications,

without independent human validation,

the approval shall be considered procedurally invalid.

---

## 4. Reversibility Confirmation

Before deployment, confirm:

- Human intervention remains technically possible.
- Operational halt can be executed.
- Responsibility attribution is defined.

If reversibility cannot be demonstrated,
approval is invalid.
